import br.uff.ic.domain.Coupling
import br.uff.ic.domain.Project
import br.uff.ic.logger.ConsoleHandler
import br.uff.ic.logger.Logger
import br.uff.ic.logger.LoggerFactory
import br.uff.ic.mining.DataSet
import br.uff.ic.mining.Transaction
import br.uff.ic.mining.Rule
import br.uff.ic.pipelines.JsonBucket
import io.netty.util.internal.ConcurrentSet
import kotlinx.coroutines.experimental.runBlocking
import org.apache.spark.SparkConf
import org.apache.spark.api.java.JavaSparkContext
import org.apache.spark.mllib.fpm.FPGrowth
import org.apache.spark.mllib.fpm.FPGrowthModel
import java.io.File
import kotlin.streams.toList
import kotlin.system.measureTimeMillis


object ImportMining {

    val sparkContext: JavaSparkContext
    private val tempDirectory : String
    private val logger : Logger

    init {
        LoggerFactory.addHandler(ConsoleHandler())
        val sparkConf = SparkConf()
                .setAppName(APP_NAME)
                .setMaster("local[8]")
                .set("spark.executor.memory", "1g")
        sparkContext = JavaSparkContext(sparkConf)
        tempDirectory = "$LOCATION\\temp"
        logger = LoggerFactory.new(ImportMining::class.java)
    }

    @Suppress("JoinDeclarationAndAssignment")
    @JvmStatic
    fun main(args: Array<String>) {
        // TODO: bucketLocation = valor no $args, repositoryURI tb
        val bucketLocation = null
        val repositoryUri = "https://github.com/apache/tomcat"

        measureTimeMillis {
            val bucket = JsonBucket(bucketLocation ?: LOCATION)
            val project : Project
            val dataSet : DataSet
            val rules : Collection<Rule>
            val couplings : Collection<Coupling>

            logger.info("cloning the repository: $repositoryUri @ $tempDirectory")
            project = cloneRepository(tempDirectory, repositoryUri)
            logger.info("collecting imports information")
            dataSet = runBlocking { collectImports(project) }
            logger.info("learning association rules from imports information")
            rules = learnAssociationRules(dataSet, BASE_SUPPORT, BASE_CONFIDENCE)
            bucket.save("extracted-rules", rules)
            logger.info("measuring coupling from rules")
            couplings = measureCouplingInformation(rules)
            bucket.save("couplings-found", couplings)

            // TODO: analyze possbile metrics based on coupling values generated by rules
            // TODO: analyze threshold values to check for reasonable number of rules (at least 10 instances should be good)
            // TODO: delete files after complete analysis
        }.apply {
            logger.info("${toDouble() / 1000}")
        }
    }

    private fun cloneRepository(folderLocation : String, repositoryURI : String) : Project {
        val directory = File(folderLocation)

        if(directory.listFiles().count() <= 1){
            val cmd = "git clone --depth=1 $repositoryURI ${directory.absolutePath}"
            val status = Runtime.getRuntime()
                    .exec(cmd)
                    .waitFor()
            if (status != 0) {
                throw Exception("Could not clone the repository: $repositoryURI. Status=$status")
            }
        }

        return Project(directory)
    }

    private fun collectImports(project : Project) : DataSet {
        val srcs = project.parseSourceFiles()
        val projectPackages = project.listPackages()
        val localImports = ConcurrentSet<String>()
        val srcFiles = srcs.parallelStream()
                .map {
                    val local = it!!.imports.filter { clazz ->
                        projectPackages.any {
                            clazz.contains(it)
                        }
                    }.toSet()
                    localImports.apply{
                        addAll(local)
                    }
                    it!!
                }.filter { it.imports.isNotEmpty() }.toList()
        val header = localImports.sorted()
        val rows = srcFiles.map {
            Transaction(it!!.getFilePath(), it.imports.toSet()  )
        }
        return DataSet(header, rows)
    }

    private fun learnAssociationRules(dataSet: DataSet, minimumSupport : Double, minimumConfidence : Double) : Collection<Rule> {
        val algorithm = FPGrowth()
        algorithm.setMinSupport(minimumSupport)
        algorithm.setNumPartitions(10)
        val fpGrowthModel: FPGrowthModel<String> = algorithm.run(dataSet.toRDD())
        val rules = mutableListOf<Rule>()
        for (rule in fpGrowthModel.generateAssociationRules(minimumConfidence).toLocalIterator().toIterable()) {
            rules.add(Rule.fromSparkRule(rule, dataSet))
        }
        return rules
    }

    private fun measureCouplingInformation(rules : Collection<Rule>) : Collection<Coupling>{
        return rules.flatMap { it.items }
                    .associateBy({it}, {item -> rules.filter { it.items.contains(item) }})
                    .map { Coupling(it.key, it.value) }
    }
}